{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jira Chatbot\n",
    "\n",
    "This application aims to provide efficient and intelligent support to both your development team and clients by answering questions, offering project insights, and assisting with common tasks and known issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import pinecone\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV = os.environ.get(\"PINECONE_ENV\")\n",
    "GRADIO_USERNAMES = os.getenv(\"GRADIO_USERNAMES\").split(',')\n",
    "GRADIO_PASSWORDS = os.getenv(\"GRADIO_PASSWORDS\").split(',')\n",
    "\n",
    "# Set up authentication for Gradio\n",
    "auth_tuples = list(zip(GRADIO_USERNAMES, GRADIO_PASSWORDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Pinecone and Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Pinecone\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "\n",
    "index_name = \"jira-demo\"\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_row_to_sentence(row):\n",
    "    \"\"\"Converts a row from a CSV file to a sentence.\"\"\"\n",
    "    sentence = \"The ticket {} that is a {}, is assigned to {}, it is currently {} and has the following description: {}\".format(\n",
    "        row[\"Summary\"], row[\"\\ufeffIssue Type\"], row[\"Assignee\"], row[\"Status\"], row[\"Description\"]\n",
    "    )\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def create_or_load_index(index_name, force_recreate=False):\n",
    "    if force_recreate and index_name in pinecone.list_indexes():\n",
    "        # If we need to force recreate, and the index already exists, delete it\n",
    "        pinecone.delete_index(index_name)\n",
    "\n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        # Now we create the index if it doesn't exist (or if we just deleted it)\n",
    "        pinecone.create_index(\n",
    "            name=index_name,\n",
    "            metric='cosine',\n",
    "            dimension=1536\n",
    "        )\n",
    "\n",
    "        print(\"Loading data...\")\n",
    "\n",
    "        # Load and parse data\n",
    "        with open(\"./data/data.csv\", encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            texts = []\n",
    "            for row in reader:\n",
    "                sentence = convert_row_to_sentence(row)\n",
    "                texts.append(sentence)\n",
    "\n",
    "        # Initialize Pinecone vector store\n",
    "        vectorstore = Pinecone.from_texts(\n",
    "            texts, embeddings, index_name=index_name)\n",
    "    else:\n",
    "        # Initialize Pinecone vector store\n",
    "        vectorstore = Pinecone.from_existing_index(index_name, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define vector store & LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use our function, e.g. with force_recreate=True if we want to regenerate the index\n",
    "vectorstore = create_or_load_index(index_name, force_recreate=False)\n",
    "\n",
    "# If we pass in a model explicitly, we need to make sure it supports the OpenAI function-calling API.\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Chat Prompt and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_msgs = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a support assistant that provides end-user support for a mobile app project called \\\"Hyer\\\". Your role is to help answer user questions about the functionality of the app as well as to help them complete common tasks in the app as well troubleshoot known issues.\"\n",
    "    ),\n",
    "    SystemMessage(\n",
    "        content=\"You are provided as context a set of JIRA tickets that might be relevant to the user's question. JIRA tickets were IssueType is Task or Story describe the intended behavior of the app. JIRA tickets that have IssueType of Bug are known defects in the app.\"\n",
    "    ),\n",
    "    SystemMessagePromptTemplate.from_template(\"{context}\"),\n",
    "    SystemMessage(content=\"Tip: JIRA tickets that have a Status of Done should already be present in app. For JIRA tickets that are Bugs and are not Done, they also may contain steps to workaround the issue..\"),\n",
    "    SystemMessage(content=\"Tip: If you don't know the answer, you can reply with 'This seems to be an unknown issue, please report it to the project manager.'. Don't try to make up an answer.\"),\n",
    "    SystemMessage(\n",
    "        content=\"History:\"\n",
    "    ),\n",
    "    SystemMessagePromptTemplate.from_template(\"{chat_history}\"),\n",
    "    HumanMessage(\n",
    "        content=\"Message:\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=prompt_msgs, input_variables=[\"context\", \"input\", \"chat_history\"]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"input\")\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    query = input(\"Enter your query: \")  # Make it interactive\n",
    "\n",
    "    # Search for relevant tickets\n",
    "    result = vectorstore.similarity_search(query)\n",
    "\n",
    "    prompt.format(context=result[0].page_content, input=query, chat_history=memory.buffer)\n",
    "\n",
    "    response = chain.run(input=query, context=result[0].page_content, chat_history=memory.buffer)\n",
    "\n",
    "    print(\"AI Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
