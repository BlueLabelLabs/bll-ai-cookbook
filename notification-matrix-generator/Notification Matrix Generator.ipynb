{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notifications Matrix Generator\n",
    "\n",
    "This application provides a user-friendly interface to generate notification strategies based on various parameters like app category, product features, special app features, target audience, and tone of voice. It leverages the power of OpenAI's GPT model and the PromptLayer API to generate these strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import PromptLayerChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import os\n",
    "import promptlayer\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptlayer.api_key = os.environ.get(\"PROMPTLAYER_API_KEY\")\n",
    "openai = promptlayer.openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GPT model and PromptLayer Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-4\"\n",
    "TEMPERATURE = 0.7\n",
    "PROMPTLAYER_TAG=\"NotificationsMatrixGenerator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Desired Data Structure Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notification(BaseModel):\n",
    "    User_Segment: str = Field(description=\"the user segment for the notification\")\n",
    "    Business_Goal: str = Field(description=\"the business goal associated with the user segment\")\n",
    "    Notification_Type: str = Field(description=\"the type of notification to be sent\")\n",
    "    Timing_Rule: str = Field(description=\"the rule for when the notification should be sent\")\n",
    "    Generated_Message: str = Field(description=\"the message to be sent in the notification\")\n",
    "    Justification: str = Field(description=\"the reason for sending the notification\")\n",
    "\n",
    "class List_of_Notifications(BaseModel):\n",
    "    notifications: List[Notification]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the parser + inject instructions into the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=List_of_Notifications)\n",
    "format_instructions = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LLM Response from Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_response_from_template(template, **kwargs):\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=list(kwargs.keys()),\n",
    "        template=template,\n",
    "        partial_variables={\"format_instructions\": format_instructions}\n",
    "    )\n",
    "    llm = PromptLayerChatOpenAI(model=GPT_MODEL, pl_tags=[PROMPTLAYER_TAG])\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    response = llm_chain.predict(**kwargs)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"As an expert in mobile app notification strategies and adhering to OneSignal best practices:\n",
    "\n",
    "Consider the following app information:\n",
    "- Category: {app_category}\n",
    "- Special Features: {special_features}\n",
    "- Product Features: {product_features}\n",
    "- Target Audience: {target_audience}\n",
    "- Tone of Voice: {tone_of_voice}\n",
    "\n",
    "Considering industry best practices and OneSignal guidelines, provide a comprehensive list of notifications with each item containing the following information:\n",
    "- User Segment\n",
    "- Business Goal\n",
    "- Notification Type\n",
    "- Timing Rule\n",
    "- Generated Message\n",
    "- Justification\n",
    "\n",
    "format_instructions: {format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Input parameters to run the model\n",
    "\n",
    "Example inputs:\n",
    "1. **App Category**: Education\n",
    "2. **Product Features**: Vocabulary Lessons, Grammar Tips, Practice Exercises, Daily Quizzes\n",
    "3. **Special App Features**: Subscriptions, Learning Tracks/Courses, Daily/Weekly Challenges\n",
    "4. **Target Audience**: Adults\n",
    "5. **Tone of Voice**: Friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_category = input(\"Enter the App Category: \").strip()\n",
    "special_features = input(\"Enter the Special Features: \").strip()\n",
    "product_features = input(\"Enter the Product Features: \").strip()\n",
    "target_audience = input(\"Enter the Target Audience: \").strip()\n",
    "tone_of_voice = input(\"Enter the Tone of Voice: \").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate response based on inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_llm_response_from_template(template=prompt_template, app_category=app_category, special_features=special_features, product_features=product_features, target_audience=target_audience, tone_of_voice=tone_of_voice)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
