{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496d45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import PromptLayerChatOpenAI\n",
    "from langchain.chains import SimpleSequentialChain, LLMChain, SequentialChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.memory.simple import SimpleMemory\n",
    "from langchain.document_loaders import RedditPostsLoader\n",
    "from langchain.llms import PromptLayerOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "import promptlayer\n",
    "import random\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06c17a",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1540e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register for a Reddit app API key and input the CLIENT_ID and CLIENT_SECRET here\n",
    "REDDIT_CLIENT_ID='<REDDIT_CLIENT_ID>'\n",
    "REDDIT_CLIENT_SECRET='<REDDIT_CLIENT_SECRET>'\n",
    "\n",
    "#Download your Twitter archive data export and copy the CSV into the same folder as this notebook.\n",
    "#See here for instructions on how to obtain it: https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive\n",
    "TWEET_ARCHIVE_CSV_FILE='<TWITTER DATA EXPORT>.csv'\n",
    "\n",
    "promptlayer.api_key = \"<PROMPTLAYER API KEY>\"\n",
    "openai = promptlayer.openai\n",
    "gpt_model = \"gpt-4-32k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024b29e",
   "metadata": {},
   "source": [
    "# Load Latest Headlines from Reddit\n",
    "The following code retrieves the top 20 Reddit posts from the r/worldnews sub-reddit, and concatenates them toegether into\n",
    "a newline separated string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2893f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Researchers in Denmark extract ancient DNA from a 2,900-year-old clay brick, revealing a time capsule of plant life\n",
      "\n",
      "France delivers first batch of SCALP long-range missiles to Ukraine, says ambassador\n",
      "\n",
      "Videos of an artillery ambush show Russian tanks and armor making 'opening day mistakes' and paying the price for them\n",
      "\n",
      "Finnish foreign minister Valtonen: \"Russia has ruined its relationship with Finland\"\n",
      "\n",
      "Japanese farmer has fought for decades to stay on his ancestral land in the middle of Narita airport\n",
      "\n",
      "Chinese activist Kwon Pyong, a critic of Xi Jinping, flees to South Korea on jet ski\n",
      "\n",
      "African Union suspends Niger over coup\n",
      "\n",
      "Billboards across London reveal an estimated 1 in 20 UK flights running on Russian oil\n",
      "\n",
      "/r/WorldNews Live Thread: Russian Invasion of Ukraine Day 545, Part 1 (Thread #691)\n",
      "\n",
      "Putin says Russia faces big economic challenges, must keep inflation in check\n"
     ]
    }
   ],
   "source": [
    "# load using 'subreddit' mode\n",
    "loader = RedditPostsLoader(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_CLIENT_SECRET,\n",
    "    user_agent=\"AutoTweeter2 Notebook\",\n",
    "    categories=[\"hot\"],  # List of categories to load posts from\n",
    "    mode=\"subreddit\",\n",
    "    search_queries=[\n",
    "        \"worldnews\"\n",
    "    ],  # List of subreddits to load posts from\n",
    "    number_posts=20,  # Default value is 10\n",
    ")\n",
    "reddit_posts = loader.load()\n",
    "reddit_posts_objs = [{\"id\":post.metadata[\"post_id\"],\"title\":post.metadata[\"post_title\"],\"url\":post.metadata[\"post_url\"]} for post in reddit_posts]\n",
    "\n",
    "#now we select N topics from the array\n",
    "number_to_sample=10\n",
    "selected_reddit_posts=random.sample(reddit_posts_objs,number_to_sample)\n",
    "\n",
    "selected_reddit_posts_as_text=\"\"\n",
    "for value in selected_reddit_posts:\n",
    "    selected_reddit_posts_as_text += \"\\n\\n\"+value[\"title\"]\n",
    "    \n",
    "print(selected_reddit_posts_as_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9596bb",
   "metadata": {},
   "source": [
    "# Load Tweet History from CSV File\n",
    "The following loads all of the Twitter user's previous Tweet history into an In-Memory Vector store, and then performs a similarity search against that for any Tweets which are similar to any of the new Reddit headlines that were extracted in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74808c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: now that Sochi is over, i bet we'll see Putin lay some Red Army pipe on the Ukraine.\n",
      "Tweet: oh those Chechens...\n",
      "Tweet: how long will Kofi Annan keep running between China, Syria and Moscow?\n",
      "Tweet: um, is that an air raid siren that just went off in Brooklyn? the Russians are coming!!\n"
     ]
    }
   ],
   "source": [
    "file = TWEET_ARCHIVE_CSV_FILE\n",
    "loader = CSVLoader(file_path=file,encoding=\"utf8\", csv_args={'delimiter':',','quotechar': '\"','fieldnames':['Tweet']})\n",
    "tweets = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "split_tweets = text_splitter.split_documents(tweets)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    split_tweets, \n",
    "    embeddings\n",
    ")\n",
    "\n",
    "query = \"Please return Tweets that relate to any of the following topics: \" + selected_reddit_posts_as_text\n",
    "docs = db.similarity_search(query)\n",
    "reference_tweets = \"\\n\".join([docs[i].page_content for i in range(len(docs))])\n",
    "\n",
    "print(reference_tweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e0765b",
   "metadata": {},
   "source": [
    "# Tweet Generation via LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d717ffb0",
   "metadata": {},
   "source": [
    "In the next step, both the newly queried Reddit headlines, alongside the reference Tweets identified in the vector store of past Tweet history, are then passed to a method that calls the LLM and generates a new set of Tweets. Rather than a single prompt to create the Tweets, AutoTweeter leverages two individual LLMChain objects sequenced together in LangChainâ€™s SequentialChain construct first to generate the Tweets, then apply a final filter used to moderate against inappropriate or insensitive remarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e79b72",
   "metadata": {},
   "source": [
    "## Chain 1: Generate Tweet Chain using Reddit Posts and Past Tweets as Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6ecc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Please generate {number_of_tweets_to_generate} tweets that relate to the topics delimited by <> and are similar in tone to the examples provided below. Tweets should be insightful and humorous. Tweets must not use hashtags. Format your answer as a list of Tweets, with each individual Tweet on its own line. \n",
    "\n",
    "% START OF EXAMPLE TWEETS TO MIMIC\n",
    "{example_tweets}\n",
    "% END OF EXAMPLE TWEETS TO MIMC\n",
    "\n",
    "<{topics}>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "llm = PromptLayerChatOpenAI(model=\"gpt-3.5-turbo\", pl_tags=[\"generate-tweets\", \"no-agent\"])\n",
    "number_of_tweets_to_generate = 10\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"number_of_tweets_to_generate\",\"example_tweets\",\"topics\"],template=template)\n",
    "generator_chain = LLMChain(llm=llm,prompt=prompt_template,output_key=\"proposed_tweets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eff64c",
   "metadata": {},
   "source": [
    "## Chain 2: Moderate Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c42b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 =\"\"\"\n",
    "Delimited in <> are a set of proposed Tweets, please filter out any tweets which may be offensive or insensitive.\n",
    "<{proposed_tweets}>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_template2 = PromptTemplate(input_variables=[\"proposed_tweets\"], template=template2)\n",
    "moderation_chain = LLMChain(llm=llm, prompt=prompt_template2,output_key=\"final_tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2420cf",
   "metadata": {},
   "source": [
    "## Create SequentialChain Containing Chain 1 & 2 and Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040e378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Researchers in Denmark uncover ancient secrets in a 2,900-year-old brick - forget time travel, this is the real deal!\n",
      "\n",
      "French sends Ukraine a gift - SCALP missiles. It's like a twisted game of missile monopoly.\n",
      "\n",
      "Russian tanks learn the hard way that ambushes and opening day mistakes don't mix. #Oops\n",
      "\n",
      "Finland has officially unfriended Russia. It's complicated.\n",
      "\n",
      "Japanese farmer's airport battle is like a real-life version of \"The Terminal.\" Tom Hanks would be proud.\n",
      "\n",
      "Chinese activist takes \"Jet Ski Escape\" to a whole new level. Action movie in the making?\n",
      "\n",
      "African Union suspends Niger for bad behavior. No dessert for you!\n",
      "\n",
      "Billboards in London reveal Russia's oil is fueling more than just airplanes, it's fueling controversy.\n",
      "\n",
      "/r/WorldNews brings us another thrilling chapter in the never-ending Russian invasion saga. Grab your popcorn, folks!\n",
      "\n",
      "Putin faces economic challenges and inflation. Maybe he should try selling his famous bare-chested calendars?\n"
     ]
    }
   ],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[generator_chain,moderation_chain],\n",
    "    input_variables=[\"number_of_tweets_to_generate\", \"example_tweets\", \"topics\"],\n",
    "    output_variables=[\"final_tweets\"],\n",
    "    verbose=True)\n",
    "\n",
    "result = overall_chain.run({\"number_of_tweets_to_generate\":number_of_tweets_to_generate, \"example_tweets\":reference_tweets, \"topics\":selected_reddit_posts_as_text})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
