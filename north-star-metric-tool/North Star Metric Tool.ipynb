{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# North Star Metric Tool\n",
    "\n",
    "This application provides a user-friendly interface to generate North Star Metrics and supporting metrics based on inputs provided. It leverages the power of OpenAI's GPT model and the PromptLayer API to generate these strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import PromptLayerChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import os\n",
    "import promptlayer\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptlayer.api_key = os.environ.get(\"PROMPTLAYER_API_KEY\")\n",
    "openai = promptlayer.openai\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GPT model and PromptLayer Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-4\"\n",
    "TEMPERATURE = 0.7\n",
    "PROMPTLAYER_TAG=\"NotificationsMatrixGenerator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Desired Data Structure Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(BaseModel):\n",
    "    Category: str = Field(description=\"The category of the metric\")\n",
    "    Name: str = Field(description=\"The name of the metric\")\n",
    "    Justification: str = Field(description=\"The justification of the metric\")\n",
    "    Impact: str = Field(description=\"The mid/long-term impact of the metric\")\n",
    "    \n",
    "class ListOfMetrics(BaseModel):\n",
    "    metrics: list[Metric] = Field(description=\"List of metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the parser + inject instructions into the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=ListOfMetrics)\n",
    "format_instructions = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LLM Response from Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_response_from_template(template, **kwargs):\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=list(kwargs.keys()),\n",
    "        template=template,\n",
    "        partial_variables={\"format_instructions\": format_instructions}\n",
    "    )\n",
    "    llm = PromptLayerChatOpenAI(model=GPT_MODEL, temperature=TEMPERATURE, pl_tags=[PROMPTLAYER_TAG])\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    response = llm_chain.predict(**kwargs)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=\"\"\"The North Star Playbook summary says the following: {north_start_plybook_summary}\n",
    "\n",
    "Given your role as '{user_role}' and with insights from the 'Amplitude North Star Playbook', considering the product category '{product_category}', the core value proposition '{core_value_proposition}', the leading indicator of value '{leading_indicator_of_value}', and the expected user engagement '{expected_user_engagement}', identify the most aligned North Star Metric reflecting user engagement and value realization, the relevant input metrics (2-3) in the categories of Breadth, Depth, and Frequency contributing to this North Star Metric, and the Mid/Long-term Impact on the business as this metric improves.\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "PLAYBOOK_CONTEXT=\"\"\"The Amplitude North Star Playbook provides detailed insights, guidelines, and examples for developing North Star Metrics and their associated input metrics. Here are some key points from the playbook:\n",
    "\n",
    "North Star Metric: The North Star Metric is a leading indicator of sustainable business results and customer value. It should reflect the heart of your product strategy and the value you provide to customers.\n",
    "\n",
    "Inputs: Inputs are the factors that, together, produce the North Star Metric. They are as important as the metric itself. Inputs should be influential, complementary factors that you believe most directly affect the North Star Metric and that you can influence through your product offering.\n",
    "\n",
    "Identifying Inputs: To identify Inputs, you can use techniques like mind-mapping and collaborative brainstorming. Start with your North Star Metric and note relationships and concepts that contribute to it. Inputs should have both a name and a definition.\n",
    "\n",
    "Justifying Inputs: Inputs should be things that your team can do something about. They should be actionable and within your control. It's better to focus on moving the Inputs that roll up to the North Star Metric rather than trying to directly move the North Star Metric itself.\n",
    "\n",
    "Aligning with Core Value Propositions: The North Star Metric and its Inputs should align with your core value propositions and reflect the value you provide to customers. They should be a result of the combination of things that your team can do something about.\n",
    "\n",
    "Leading Indicators of Value: The North Star Metric is a leading indicator of sustainable business results and customer value. As you see the North Star Metric change, you can expect your business results to change accordingly. The Inputs should be the influential factors that directly affect the North Star Metric and can be influenced through your product offering.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Input parameters to run the model\n",
    "\n",
    "Example inputs:\n",
    "- **User Role**: Product Manager\n",
    "- **Product Category**: Food & Drink (Restaurant Reservations)\n",
    "- **Core Value Proposition**: \"OpenTable empowers users to discover and book the perfect table every time.\"\n",
    "- **Leading Indicator of Value**: \"User bookings and successful dining experiences.\"\n",
    "- **Expected User Engagement**: \"Frequent interactions, restaurant searches, and bookings.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_role = input(\"Enter the User Role: \").strip()\n",
    "product_category = input(\"Enter the Product Category: \").strip()\n",
    "core_value_proposition = input(\"Enter the Core Value Proposition: \").strip()\n",
    "leading_indicator_of_value = input(\"Enter the Leading Indicator of Value: \").strip()\n",
    "expected_user_engagement = input(\"Enter the Expected User Engagement: \").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate response based on inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_llm_response_from_template(\n",
    "            template=PROMPT,\n",
    "            north_start_plybook_summary=PLAYBOOK_CONTEXT,\n",
    "            user_role=user_role,\n",
    "            product_category=product_category,\n",
    "            core_value_proposition=core_value_proposition,\n",
    "            leading_indicator_of_value=leading_indicator_of_value,\n",
    "            expected_user_engagement=expected_user_engagement)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
